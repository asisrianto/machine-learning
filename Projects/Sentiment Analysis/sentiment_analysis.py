# -*- coding: utf-8 -*-
"""Sentiment Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tvn5d5E5yZWNyGZe4LWC273WEO_rzTUa

# Data Diri

Nama     : Asis Rianto \
Email    : asisrianto2@gmail.com \
Username : [asisrianto](https://www.dicoding.com/users/asisrianto)

---

Dataset : [Tweet Sentiment Dataset](https://www.kaggle.com/datasets/saurabhshahane/twitter-sentiment-dataset/)

# Import The Libraries
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.model_selection import GridSearchCV
import time
import matplotlib.pyplot as plt

"""# DATA PREPARATION"""

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('/content/drive/MyDrive/Dataset/Twitter_Data.csv')

df

df = df.astype(str)

category = pd.get_dummies(df.category)
df_new = pd.concat([df, category], axis=1)
df_new = df_new.drop(columns='category')
df_new

df_new.rename(
    columns=({'-1.0':'negative','0.0':'neutral','1.0':'positive'}),
    inplace=True,
)
df_new

df = df_new.drop(columns='nan')
df

features = df['clean_text'].values
labels = df[['negative','neutral','positive']].values

feature_train, feature_test, label_train, label_test = train_test_split(features, labels, test_size=0.2)

"""# DATA PREPROCESSING

Tokenizer
"""

MAX_FEATURES = 10000
OOV_TOKEN = 'x'

tokenizer = Tokenizer(num_words=MAX_FEATURES, oov_token=OOV_TOKEN)
tokenizer.fit_on_texts(feature_train)
tokenizer.fit_on_texts(feature_test)

train_seq = tokenizer.texts_to_sequences(feature_train)
X_train = pad_sequences(train_seq)

test_seq = tokenizer.texts_to_sequences(feature_test)
X_test = pad_sequences(test_seq)

y_train = label_train
y_test = label_test

[X_train.shape, X_test.shape]

X_train = np.lib.pad(X_train, ((0,0),(X_test.shape[1] - X_train.shape[1],0)), 'constant', constant_values=(0))

[X_train.shape, X_test.shape]

"""# MODEL SELECTION

Architecture
"""

INPUT_DIM = 10000
OUTPUT_DIM = 32
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=INPUT_DIM, output_dim=OUTPUT_DIM),
    tf.keras.layers.LSTM(64, dropout=0.5, recurrent_dropout=0.2 ),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(3, activation='softmax')
])

model.summary()

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

"""Callbacks"""

filepath="weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5"
model_checkpoint = tf.keras.callbacks.ModelCheckpoint(
    filepath, monitor='val_loss',
    verbose=0,
    save_best_only=True,
    mode='auto'
)

early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor="val_loss",
    min_delta=0,
    patience=10,
    verbose=0,
    mode="auto",
    baseline=None,
    restore_best_weights=True
)

"""# TRAINING THE MODEL"""

NUM_EPOCHS = 5

start = time.time()
history = model.fit(X_train, y_train, 
                    epochs=NUM_EPOCHS, 
                    validation_data=(X_test, y_test),
                    callbacks=[model_checkpoint, early_stopping],  
                    verbose=2)
stop = time.time()
print(f'{stop-start}')

"""Visualization of accuracy and loss"""

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.style.use('seaborn-whitegrid')
plt.subplots(1, 2, figsize=[20, 5])
plt.subplot(1,2,1)
acc = plt.plot(epochs, acc, label='Training Accuracy')
val_acc = plt.plot(epochs, val_acc, label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.legend(loc=0)
plt.subplot(1,2,2)
loss = plt.plot(epochs, loss, label='Training Loss')
val_loss = plt.plot(epochs, val_loss, label='Validation Loss')
plt.title('Training and Validation Loss')
plt.legend(loc=0)

#plt.savefig('proposed_model.png')
plt.show()

"""# Save The Model"""

model.save("sentiment_analysis.h5")
# -*- coding: utf-8 -*-
"""Weather Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1b9iSRefil60vWI8KeVpdojb_W1fXDeOz

# Data Diri

nama: Asis Rianto \
email: asisrianto2@gmail.com \
username: [asisrianto](https://www.dicoding.com/users/asisrianto) \

# Import The Libraries
"""

import time 
import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn import metrics
from keras.layers import Dense, LSTM
from keras.preprocessing.sequence import TimeseriesGenerator
from keras.layers import Dense, LSTM
import matplotlib.pyplot as plt

"""# DATA PREPARATION"""

from google.colab import drive
drive.mount('/content/drive')

dataset = pd.read_csv('/content/drive/MyDrive/Dataset/San_Diego_Daily_Weather_Data_2014.csv')
dataset.head()

dataset.info()

data = dataset[:20000]
data = data[['hpwren_timestamp','air_temp']].copy()
data

data['Date'] = pd.to_datetime(data['hpwren_timestamp']).dt.strftime('%Y-%m-%d')
data = data.drop('hpwren_timestamp', axis=1)
data

data = data.set_index('Date')
data.head()

data.describe()

data.isnull().sum()

plt.figure(figsize=(21, 5))
plt.plot(data)
plt.title('San Diego Weather')
plt.xlabel('Date')
plt.ylabel('Temperature')
plt.show()

"""# DATA PREPROCESSING"""

data_train, data_test = train_test_split(data.values, test_size=0.2, shuffle=False)

feature_range=(0,1)

scaler = MinMaxScaler(feature_range=(0,1))
train_scale = scaler.fit_transform(data_train.reshape(-1, 1))
test_scale = scaler.fit_transform(data_test.reshape(-1, 1))

LOOK_BACK = 20
train_set = TimeseriesGenerator(train_scale, train_scale, length=LOOK_BACK, batch_size=20)
test_set = TimeseriesGenerator(test_scale, test_scale, length=LOOK_BACK, batch_size=20)

"""# MODEL SELECTION

## Architecture
"""

model = tf.keras.models.Sequential([
    tf.keras.layers.LSTM(64, activation='relu', return_sequences=True, input_shape=(LOOK_BACK, 1)),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(1)
])

optimizer = tf.keras.optimizers.SGD(learning_rate=1.0000e-04, momentum= 0.9)
model.compile(loss=tf.keras.losses.Huber(), 
              optimizer=optimizer, 
              metrics=['mae'])

"""## Callbacks"""

threshold_mae = (train_scale.max()-train_scale.min()) * (10/100)
threshold_mae

class callbacks(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('mae') < threshold_mae):
      self.model.stop_training = True #stop training if mae < threshold_mae
      print('\nMAE is under 10% of data scale')
callbacks = callbacks()

"""# MODEL TRAINING"""

EPOCHS=10

start = time.time()
history = model.fit(train_set, 
                    epochs=EPOCHS, 
                    callbacks=[callbacks],
                    validation_data=test_set,
                    verbose=1)
stop = time.time()

print(f'{stop-start}')

"""Visualization"""

plt.style.use('seaborn-whitegrid')
plt.subplots(1, 2, figsize=[20, 5])

plt.subplot(1,2,1)
plt.plot(history.history['mae'])
plt.plot(history.history['val_mae'])
plt.title('MAE')
plt.xlabel('epocs')
plt.ylabel('mae')
plt.legend(['train','test'],loc=0)

plt.subplot(1,2,2)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss')
plt.xlabel('epocs')
plt.ylabel('mae')
plt.legend(['train','test'],loc=0)


#plt.savefig('proposed_model.png')
plt.show()

"""# Save The Model"""

model.save('stock_price_forecasting.h5')